---
title: "coln_hw4"
author: "Di LU"
date: "2017å¦<a4><a0><9e><b4>10é—<81><ba><88><88>9é—<81><ba><83><a5>"
output:
  pdf_document: 
    latex_engine: xelatex
  html_document: default
  word_document: default
---

## Stats500 Homework 4
#### *Di Lu, Oct.11, 2017*

### Q1. Based on Chapter 4, Problem 1(p. 97) 
#### 1. build a linear model of total on expend, salary, ratio and takers
```{r}
data(sat,package = "faraway")
lmod <- lm(total~takers+ratio+salary+expend, data = sat)
#summary(lmod)
```

#### 2. Check the constant variance assumption for the errors and for evidence of non-linearity via residual plots, and adjust model as appropriate
```{r}
# check for linearity
par(mfrow=c(1,2))
plot(fitted(lmod),residuals(lmod),xlab="Fitted Values",ylab="Residuals")
abline(h=0) # a diagnostic residual plot
plot(fitted(lmod),rstudent(lmod),xlab="Fitted Values",ylab="Studentized Residuals")
abline(h=0)
```
Plot residual against fitted values, we can see residuals are not constant symmetrical variation. It has some non-linear relationship, which looks like quadratic. And Seen from the studentized residuals against fitted values, also shows constant variation do not hold.
Then we plot residuals against predictors in the model, we can see in residuals against takes plot, it shows a strong trend for a U-shape relationship, thus leading to non-linearity of residuals. The other three plots are roughly symmetric.

```{r}
# discover which predictor has a non-linear relationship with the response 
par(mfrow=c(2,2))
plot(takers,residuals(lmod),xlab="Takers",ylab="Residuals")
abline(h=0)
plot(ratio,residuals(lmod),xlab="Ratio",ylab="Residuals")
abline(h=0)
plot(salary,residuals(lmod),xlab="Salary",ylab="Residuals")
abline(h=0)
plot(expend,residuals(lmod),xlab="Expend",ylab="Residuals")
abline(h=0)
```

To address this quadratic relationship, we add a quadratic term of takers to the model, which is total~takers+I(takers^2)+ratio+salary+expend. Plot residual against fitted values in this model, then there is no clear sign of non-linearity. The studentized residuals against fitted values is like a constant variation relationship and a quick test to check constant variance (p=0.9746) shows not enough evidence to reject constant variation at significance level 5%.

```{r}
lmod2 <- lm(total~takers+I(takers^2)+ratio+salary+expend)

par(mfrow=c(1,2))
plot(fitted(lmod2),residuals(lmod2),xlab="Fitted Values",ylab="Residuals")
abline(h=0) # a diagnostic residual plot
plot(fitted(lmod2),rstudent(lmod2),xlab="Fitted Values",ylab="Studentized Residuals")
abline(h=0)
summary(lm(lmod2$residuals~lmod2$fitted.values))
summary(lm(rstandard(lmod2)~lmod2$fitted.values))
```

#### 3. Check the normality assumption
We use QQ-plot to check normality assumption of residuals. Residuals follow the "ideal normal distribution" line approximately, indicates normality of residuals. Shapiro test (p=0.9384) shows not enough evidence to reject normality hypothesis, which doubles the resolution.
```{r}
qqnorm(lmod2$residuals,ylab = "Residuals")
qqline(lmod2$residuals)
shapiro.test(lmod2$residuals)
```

#### check correlated errors
We plot errors at time t against time t+1 to check correlated error, in the plot there is no clear correlation. The linear regression and test(p=0.07523) at significance level 5% shows not enough evidence to reject uncorrelated errors.
```{r}
n <- length(residuals(lmod2))
plot(tail(residuals(lmod2),n-1) ~ head(residuals(lmod2),n-1), xlab=
       expression(hat(epsilon)[i]),ylab=expression(hat(epsilon)[i+1]))
abline(h=0,v=0,col=grey(0.75))
summary(lm(tail(residuals(lmod2),n-1) ~ head(residuals(lmod2),n-1) -1))
```

#### 4. Check for large leverage points
We would like to identify unusually large values of the leverage in half-normal plot. We can see obs.7 and 44 diverge substantially from the rest of the data. By rule of thumb, we have 4 data points whose leverages are greater than 2(p+1)/n = 2(5+1)/50=0.24, they are 2, 5, 7, 44.
On the other hand, studentized residuals adjust residuals to equal variance, thus at higher leverage points can correct natural non-constant variance in residuals
```{r}
par(mfrow=c(1,2))
halfnorm(lm.influence(lmod2)$hat,nlab=2,ylab = "Leverage",main="Half-normal plot")
abline(h=2*(5+1)/50)
qqnorm(rstandard(lmod2))
abline(0,1)
sat[c(2,5,7,44),]
```

#### 5. Check for outliers
We compute jacknife residuals for the sat data and pick out the largest. By applying Bonferroni correction criteria at a level alpha=5% test(that is 0.05/50 = 0.001), p-value for largest studentized residuals is 0.005258, we don't have enough evidence to reject null hypothes point 48 is an outlier. For other points, we can also not reject.
```{r}
ti<-rstudent(lmod2)
max(abs(ti))
sat[which.max(abs(ti)),]
2*(1-pt(max(abs(ti)),df=50-(5+1)-1))
0.05/50
```

### 2. (a)




### 2. (b) studentized residual instead of standard residuals
Because in studentize residuals, we scale residuals by its variance (           ,specific to its leverage), so that ri can be equal variance. This helps us disgnose non-constant variance better.
Standard residuals scale residuals by SE of residuals, so that zi shows the standardized size of residual in the population. Both do the work of standardization, help us judge the size easily. And, shown in the below plots, results are little difference. 
But in studentize residuals, leverages are used in scaling residuals, ensuring the equal variance. In standard residual, every residual scaled by teh same SE doesnot help compare variances. sHowever, studentize residuals can only correct variance in homoscedasticity situations, otherwise we cannot be sure.

```{r}
par(mfrow=c(1,3))
plot(fitted(lmod2),residuals(lmod2),xlab="Fitted Values",ylab="Residuals")
abline(h=0)
plot(fitted(lmod2),rstudent(lmod2),xlab="Fitted Values",ylab="Studentized Residuals")
abline(h=0)
plot(fitted(lmod2),rstandard(lmod2),xlab="Fitted Values",ylab="Standard Residuals")
abline(h=0) # a diagnostic residual plot

```




